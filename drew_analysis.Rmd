---
title: "Rent and Inventory SARIMA and ETS"
output: html_notebook
---

```{r}
rm(list=ls())
library(tidyverse)
library(tseries)
library(forecast)
library(TSA)
library(dplyr)
```

### Load and inspect data

```{r}
# source: https://streeteasy.com/blog/data-dashboard/?agg=Total&metric=Inventory&type=Rentals&bedrooms=Any%20Bedrooms&property=Any%20Property%20Type&minDate=2010-01-01&maxDate=2022-12-01&area=Flatiron,Brooklyn%20Heights

# note that we can also get breakdown by bedrooms if we want

# set up generalizable path without local path hard coded
base_path <- system('git rev-parse --show-toplevel', intern = T)

# rental index - one for each of four real boroughs
# note: we won't use the rental index as it is already smoothed via ARIMA
rental_index_raw <- read.csv(paste0(base_path, '/data/rentalIndex_All.csv'))
# median asking rent - four real boroughs + 155 neighborhoods
median_rent_raw <- read.csv(paste0(base_path, '/data/medianAskingRent_All.csv'))
# rental inventory - four real boroughs + 155 neighborhoods
inventory_raw <- read.csv(paste0(base_path, '/data/rentalInventory_All.csv'))

```

```{r}
rental_index_manhattan <- ts(rental_index_raw$Manhattan,
                             start=c(2007,1),
                             frequency=12)

tsdisplay(rental_index_manhattan)

median_rent_manhattan <- median_rent_raw %>% 
  filter(areaName=="Manhattan") %>%
  unlist() %>% as.numeric() %>% 
  na.omit() %>% 
  ts(start=c(2010,1),frequency=12)

tsdisplay(median_rent_manhattan)

inventory_manhattan <- inventory_raw %>% 
  filter(areaName=="Manhattan") %>% 
  unlist() %>% as.numeric() %>% 
  na.omit() %>%
  ts(start=c(2010,1),frequency=12)

tsdisplay(inventory_manhattan)

rent_train <- window(median_rent_manhattan, start=2010, end=c(2020,1))
inventory_train <- window(inventory_manhattan, start=2010, end=c(2020,1))
rent_test <- window(median_rent_manhattan, start=c(2020,2), end=c(2022,12))
inventory_test <- window(inventory_manhattan, start=c(2020,2), end=c(2022,12))

# Box-Cox transformed
tsdisplay(BoxCox(rent_train,lambda='auto'))
tsdisplay(BoxCox(inventory_train,lambda='auto'))
```

```{r}
#save(inventory_manhattan,file='data/inventory_manhattan.RData')
#save(median_rent_manhattan,file='data/median_rent_manhattan.RData')
```


```{r}
plot((rent_train-mean(rent_train))/var(rent_train)/30)
lines((inventory_train-mean(inventory_train))/var(inventory_train),col='red')
```

```{r}
rent_stationary <- diff(BoxCox(rent_train,lambda=0),differences=1,lag=1)
inventory_stationary <- diff(BoxCox(inventory_train,lambda=0),differences=1,lag=1)

plot((rent_stationary-mean(rent_stationary))/var(rent_stationary))
lines(((inventory_stationary-mean(inventory_stationary)))/var(inventory_stationary),col='red')
```


### SARIMA

```{r}
# median rent SARIMA
rent_lambda = BoxCox.lambda(rent_train)
rent_sarima <- auto.arima(rent_train,lambda=rent_lambda,trace=TRUE)
checkresiduals(rent_sarima)
summary(rent_sarima)
```
Best rent SARIMA: nonseasonal first difference, seasonal AR(2), no drift. This is a parsimonous model with white noise residuals. Adding drift, nonseasonal AR(1) and seasonal MA(1) only slightly increase AICc. RMSE 31.8, MAE 24,08806, MAPE 0.7533599.


```{r}
inventory_lambda = 0  # Note: As determined in Wesley's code, we will just use a log transform for the inventory series.
inventory_sarima <- auto.arima(inventory_train,lambda=inventory_lambda,trace=TRUE)
checkresiduals(inventory_sarima)
summary(inventory_sarima)
```

Best inventory SARIMA: nonseasonal first difference, seasonal first-differenced MA(1). Residuals are mostly white noise - possibly some quarterly / two-year autocorrelations, but might also just be multiple testing (Ljung-Box doesn't reject). Similarly to above, there are a number of models with very close AICc, though none with drift. RMSE 673.5361, MAE 481.7169, MAPE 2.686797.


### ETS

```{r}

rent_ets <- ets(rent_train, lambda = rent_lambda)  # note that we get AAA without lambda
summary(rent_ets)
checkresiduals(rent_ets)

inventory_ets <- ets(inventory_train)  # don't force lambda, because that forces additive model
summary(inventory_ets)
checkresiduals(inventory_ets)
```
Rent ETS: AAA (additive error, trend, seasonality).
    alpha = 0.9996 
    beta  = 2e-04 
    gamma = 3e-04 
    phi   = 0.9744 
Dominated by error, with very little trend or seasonality. Only slightly damped. Residuals mostly look like white noise, maybe 1.5 year seasonality, but Ljung-Box rejects at high significance level. Training RMSE 29.52856, MAE 22.48471, MAPE 0.7053597.

Inventory ETS: MAM (multiplicative error, additive trend, multiplicative seasonality).
    alpha = 0.9884 
    beta  = 0.0875 
    gamma = 1e-04 
    phi   = 0.98
Dominated by error, with some trend contribution and very little seasonality. Only slightly damped. Residuals mostly look like white noise but Ljung-Box rejects at high significance level. RMSE 621.3574, MAE 469.1133, MAPE 2.705515.


### Cross-validation

```{r}
### DEFINE MODELS HERE:

rent_SARIMA_model = function(training_data){
  return(Arima(
    training_data,order=c(0,1,0),seasonal=c(2,0,0),
    include.drift=FALSE,lambda=rent_lambda,method='CSS-ML'))}

inventory_SARIMA_model = function(training_data){
  return(Arima(
    training_data,order=c(0,1,0),seasonal=c(0,1,1),method='CSS-ML'))}

rent_ets_model = function(training_data){
  return(ets(training_data,model="MAN"))}

inventory_ets_model = function(training_data){
  return(ets(training_data,model="MAA"))}

### cross-validation helper functions

add_NAs_to_list <- function(lst) {
  n <- length(lst)
  if (n >= 12) {
    return(lst)
  }
  return(c(lst, rep(NA, 12 - n)))
}

predict_and_forecast = function(model,series,i,last_training_point,n_forecast,window_type){
  if (window_type=="expanding"){
    training_window <- ts(series[1:last_training_point],frequency=12)
  } else if (window_type=="sliding"){
    training_window <- ts(series[i:last_training_point],frequency=12)}
  last_test_point <- ifelse(
    last_training_point+n_forecast<=length(series),
    last_training_point+n_forecast,
    length(series))
  true_future <- series[(last_training_point+1):(last_training_point+n_forecast)]
  model_trained <- model(training_window)
  model_aicc <- model_trained$aicc
  forecast_error <- forecast(model_trained,h=length(true_future))$mean-true_future 
  return(list(model_aicc,add_NAs_to_list(forecast_error)))
}

# cross-validation function
cross.validate = function(model,series,n_window,n_forecast){

  # initialize
  iterations <- length(series)-n_window
  model_aicc_expanding <- vector(mode='list', length=iterations)
  error_expanding <- vector(mode='list', length=iterations)
  model_aicc_sliding <- vector(mode='list', length=iterations)
  error_sliding <- vector(mode='list', length=iterations)

  # expanding
  for (i in 1:iterations){
    iteration_output <- predict_and_forecast(model,series,i,i+n_window-1,n_forecast,"expanding")
    model_aicc_expanding[i] <- iteration_output[1]
    error_expanding[[i]] <- iteration_output[2]
  }
  
  # sliding
  for (i in 1:iterations){
    iteration_output <- predict_and_forecast(model,series,i,i+n_window-1,n_forecast,"sliding")
    model_aicc_sliding[i] <- iteration_output[1]
    error_sliding[[i]] <- iteration_output[2]
  } 
  
  return(list(model_aicc_expanding,error_expanding,model_aicc_sliding,error_sliding))
}

# plotting
generate.plots = function(output_arima, output_ets){
  arima_expanding_errors <- data.frame(matrix(unlist(output_arima[[2]]), ncol = 12, byrow = TRUE))
  arima_sliding_errors <- data.frame(matrix(unlist(output_arima[[4]]), ncol = 12, byrow = TRUE))
  ets_expanding_errors <- data.frame(matrix(unlist(output_ets[[2]]), ncol = 12, byrow = TRUE))
  ets_sliding_errors <- data.frame(matrix(unlist(output_ets[[4]]), ncol = 12, byrow = TRUE))

  # Mean Absolute Forecast Error (MAE) vs forecast horizon
  plot(1:12,colMeans(abs(arima_expanding_errors),na.rm=TRUE),'l',
     main='expanding arima MAE',xlab='horizon',ylab='MAE')
  plot(1:12,colMeans(abs(arima_sliding_errors),na.rm=TRUE),'l',
     main='sliding arima MAE',,xlab='horizon',ylab='MAE')

# Root-square Forecast Error (RMSE) vs forecast horizon
  plot(1:12,sqrt(colMeans((arima_expanding_errors)**2,na.rm=TRUE)),'l',
     main='expanding arima RSME',xlab='horizon',ylab='RMSE')
  plot(1:12,sqrt(colMeans((arima_sliding_errors)**2,na.rm=TRUE)),'l',
     main='sliding arima RSME',,xlab='horizon',ylab='RMSE')

  # Mean Absolute Forecast Error (MAE) vs iteration
  plot(1:41,rowMeans(abs(arima_expanding_errors),na.rm=TRUE),'l',
     main='expanding arima MAE',xlab='iteration',ylab='MAE')
  plot(1:41,rowMeans(abs(arima_sliding_errors),na.rm=TRUE),'l',
     main='sliding arima MAE',xlab='iteration',ylab='MAE')

  # Root-square Forecast Error (RMSE) vs iteration
  plot(1:41,sqrt(rowMeans((arima_expanding_errors)**2,na.rm=TRUE)),'l',
     main='expanding arima RSME',xlab='iteration',ylab='RMSE')
  plot(1:41,sqrt(rowMeans((arima_sliding_errors)**2,na.rm=TRUE)),'l',
     main='sliding arima RSME',xlab='iteration',ylab='RMSE')

  # AICc vs iteration
  plot(1:41,output_arima[[1]],'l',main='expanding arima aicc',xlab='iteration',ylab='AICc')
  plot(1:41,output_arima[[3]],'l',main='sliding arima aicc',,xlab='iteration',ylab='AICc')

  # Mean Absolute Forecast Error (MAE) vs forecast horizon
  plot(1:12,colMeans(abs(ets_expanding_errors),na.rm=TRUE),'l',
     main='expanding ets MAE',,xlab='horizon',ylab='MAE')
  plot(1:12,colMeans(abs(ets_sliding_errors),na.rm=TRUE),'l',
     main='sliding ets MAE',xlab='horizon',ylab='MAE')

  # Root-square Forecast Error (RMSE) vs forecast horizon
  plot(1:12,sqrt(colMeans((ets_expanding_errors)**2,na.rm=TRUE)),'l',
     main='expanding ets RMSE',xlab='horizon',ylab='RMSE')
  plot(1:12,sqrt(colMeans((ets_sliding_errors)**2,na.rm=TRUE)),'l',
     main='sliding ets RMSE',xlab='horizon',ylab='RMSE')

  # Mean Absolute Forecast Error (MAE) vs iteration
  plot(1:41,rowMeans(abs(ets_expanding_errors),na.rm=TRUE),'l',
     main='expanding ets MAE',xlab='iteration',ylab='MAE')
  plot(1:41,rowMeans(abs(ets_sliding_errors),na.rm=TRUE),'l',
     main='sliding ets MAE',xlab='iteration',ylab='MAE')

  # Root-square Forecast Error (RMSE) vs iteration
  plot(1:41,sqrt(rowMeans((ets_expanding_errors)**2,na.rm=TRUE)),'l',
     main='expanding ets RMSE',xlab='iteration',ylab='RMSE')
  plot(1:41,sqrt(rowMeans((ets_sliding_errors)**2,na.rm=TRUE)),'l',
     main='sliding ets RMSE',xlab='iteation',ylab='RMSE')

  # AICc vs iteration
  plot(1:41,output_ets[[1]],'l',main='expanding ets aicc',xlab='iteration',ylab='AICc')
  plot(1:41,output_ets[[3]],'l',main='sliding ets aicc',xlab='iteration',ylab='AICc')
}
```

```{r}
# rent
output_arima <- cross.validate(rent_SARIMA_model,rent_train,80,12)
output_ets <- cross.validate(rent_ets_model,rent_train,80,12)
generate.plots(output_arima,output_ets)
```

```{r}
# inventory
output_arima <- cross.validate(inventory_SARIMA_model,inventory_train,80,12)
output_ets <- cross.validate(inventory_ets_model,inventory_train,80,12)
generate.plots(output_arima,output_ets)
```

